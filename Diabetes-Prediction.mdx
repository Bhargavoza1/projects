---
title: 'Practice project on Diabetes Prediction'
image: https://raw.githubusercontent.com/Bhargavoza1/projects/main/images/Diabetes-Prediction/MLP.png
description: This practice project aims to explore predictive analytics using a diabetes dataset, employing two distinct algorithms...
date: '2024-01-17'
tags: ['ai','neuralnetwork','deeplearning','machinelearning','ml','project']
---

Diabetes, a chronic metabolic disorder, poses a substantial global health challenge. Accurate and timely prediction of diabetes onset is crucial for preventive interventions and personalized patient care. In this project, 
we will harness the potential of machine learning to develop predictive models capable of identifying patterns within a diabetes dataset. The choice of Logistic Regression and MLP as the algorithms for comparison is motivated by their distinct methodologies, 
allowing us to evaluate their respective strengths and weaknesses in handling complex medical data.

Throughout this project, we will outline the preprocessing steps, feature engineering, and model training processes for both Logistic Regression and MLP. 
The comparative analysis will not only shed light on their predictive capabilities but also offer insights into the interpretability and generalizability of each model. 
The ultimate goal is to equip practitioners and enthusiasts with a deeper understanding of the nuances involved in selecting the appropriate machine learning algorithm for diabetes prediction tasks.

- **Interpretability**: Logistic Regression is generally more interpretable than complex models like MLP. The coefficients in Logistic Regression directly correspond to the impact of each feature on the output, 
providing a clear understanding of the model's decision process. MLP, being a neural network with multiple layers, can be more challenging to interpret due to its intricate architecture.\
Interpretability helps you see the impact of each piece of information on the model's output. For instance, if a model predicts loan approval, interpretability shows you how factors like income, credit score, and debt influence the decision.

- **Generalizability**: The generalizability of the models will be assessed based on their performance on unseen data. A model that can generalize well to new diabetes cases beyond the training dataset is preferable, 
as it indicates the ability to capture underlying patterns common to different instances of the problem. The comparison between Logistic Regression and MLP will help evaluate which model is more effective in terms of generalization for the given diabetes dataset.

This practice project aims to explore predictive analytics using a diabetes dataset, employing two distinct algorithms for comparison – Logistic Regression and Multi-Layer Perceptron (MLP).

# Diabetes Prediction

Let’s start writing practice project in jupyter notebook.
I am using  [pima-indians-diabetes-database](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database)


```
pip install -r requirements.txt
```
This command reads the requirements.txt file and installs all the specified dependencies.

Make sure you have Python and pip installed on your system, and the pip executable is added to your system's PATH.

```Python
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats

from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_recall_curve, auc, precision_score, recall_score, roc_curve, roc_auc_score

import tensorflow as tf
```

Reading dataset from the local file.
```Python
diabetes_DS = pd.read_csv('data/diabetes.csv')
```

Now, Displays the first few rows of the dataset, statistical summary, shape (number of rows and columns), and the count of different classes in the **Outcome** column (0 - Non-Diabetic, 1 - Diabetic).

```Python
diabetes_DS.head()
```
<CustomImage src="https://raw.githubusercontent.com/Bhargavoza1/projects/main/images/Diabetes-Prediction/dshead.png"  alt=""  width={941} height={234} />

```Python
diabetes_DS.describe()
```
<CustomImage src="https://raw.githubusercontent.com/Bhargavoza1/projects/main/images/Diabetes-Prediction/dsdescribe.png"  alt=""  width={1000} height={348} />

```Python
diabetes_DS.shape
```
(768, 9)

```Python
diabetes_DS['Outcome'].value_counts()
```
Outcome \
0    500 \
1    268

0 - Non-Diabetic \
1 - Diabetic


The provided code uses the groupby function to group a DataFrame named diabetes_DS by the 'Outcome' column, calculates the mean for each group, and transposes the result. 
The resulting DataFrame df contains columns for 'Outcome' 0 and 1, with rows representing mean values for each original column in the dataset.
```Python
df = diabetes_DS.groupby('Outcome').mean().T
df
```
<CustomImage src="https://raw.githubusercontent.com/Bhargavoza1/projects/main/images/Diabetes-Prediction/groupbyt.png"  alt=""  width={336} height={275} />

This formula calculates the percentage difference between values in columns labeled 0 and 1 in the DataFrame 'df'. The result is then stored in a new column labeled '%diff'. This formula is commonly used to measure the relative difference between two values.
```Python
df['%diff'] = (abs(df[0] - df[1] )/ ((df[0] + df[1])/2)) *100
df
```
<CustomImage src="https://raw.githubusercontent.com/Bhargavoza1/projects/main/images/Diabetes-Prediction/groupbytd.png"  alt=""  width={410} height={275} />

Dropping the column named 'Outcome' from the DataFrame diabetes_DS.
```Python
data = diabetes_DS.drop(columns= 'Outcome', axis=1)
data.head()
```

```Python
data.hist(bins=30, figsize=(15,10))
plt.show()
```
<CustomImage src="https://raw.githubusercontent.com/Bhargavoza1/projects/main/images/Diabetes-Prediction/hist.png"  alt=""  width={1000} height={834} />

Computes the correlation matrix for the features in the dataset and visualizes it using a heatmap. This helps to identify relationships between different features.
```Python
corr_matrix = data.corr()
corr_matrix
```
<CustomImage src="https://raw.githubusercontent.com/Bhargavoza1/projects/main/images/Diabetes-Prediction/corr.png"  alt=""  width={900} height={272} />

A correlation coefficient of 0.54, representing the maximum correlation between the variables "Pregnancies" and "Age," is considered moderate. This moderate correlation does not raise concerns.
```Python
sns.heatmap(corr_matrix, annot= True)
```
<CustomImage src="https://raw.githubusercontent.com/Bhargavoza1/projects/main/images/Diabetes-Prediction/corrheat.png"  alt=""  width={663} height={568} />

## Preprocessing
performing imputation for missing values in specific columns of the diabetes dataset using the median value of each respective column.

```Python
# Calculate the median value for BMI
median_bmi = diabetes_DS['BMI'].median()
# Substitute it in the BMI column of the
# dataset where values are 0
diabetes_DS['BMI'] = diabetes_DS['BMI'].replace(
    to_replace=np.nan, value=median_bmi)

median_bloodp = diabetes_DS['BloodPressure'].median()
# Substitute it in the BloodP column of the
# dataset where values are 0
diabetes_DS['BloodPressure'] = diabetes_DS['BloodPressure'].replace(
    to_replace=np.nan, value=median_bloodp)

# Calculate the median value for PlGlcConc
median_plglcconc = diabetes_DS['Glucose'].median()
# Substitute it in the PlGlcConc column of the
# dataset where values are 0
diabetes_DS['Glucose'] = diabetes_DS['Glucose'].replace(
    to_replace=np.nan, value=median_plglcconc)

# Calculate the median value for SkinThick
median_skinthick = diabetes_DS['SkinThickness'].median()
# Substitute it in the SkinThick column of the
# dataset where values are 0
diabetes_DS['SkinThickness'] = diabetes_DS['SkinThickness'].replace(
    to_replace=np.nan, value=median_skinthick)

# Calculate the median value for SkinThick
median_skinthick = diabetes_DS['Insulin'].median()
# Substitute it in the SkinThick column of the
# dataset where values are 0
diabetes_DS['Insulin'] = diabetes_DS['Insulin'].replace(
    to_replace=np.nan, value=median_skinthick)
```

**Use Z-scores to identify and filter out the outliers.**
The boxen plot for Insulin shows that the data is skewed, with a long tail of high values. This means that there are a few people with very high Insulin levels, which could be due to outliers or a different population.

```Python
diabetes_DS.boxplot(figsize=(15,10))
```

<CustomImage src="https://raw.githubusercontent.com/Bhargavoza1/projects/main/images/Diabetes-Prediction/boxplotb.png"  alt=""  width={1000} height={800} />

-  $z = \frac{{ X - \mu}}{{\sigma}}$ 
    - $Z$ is the z-score, a standardized value that tells you how many standard deviations a particular data point  $(X)$  is from the mean  $(\mu)$
    - $X$ is the raw score or data point you're interested in.
    - $\mu$ is the mean of the data set, which is the average value.
    - ${\sigma}$ is the standard deviation, a measure of how spread out the values in a data set are.
- If the Z-score is positive, the data point is above the mean.
- If the Z-score is negative, the data point is below the mean.
- A Z-score of 0 indicates that the data point's value is exactly at the mean.
- By setting a threshold for Z-scores, you can identify and potentially remove data points that deviate significantly from the mean, helping to detect outliers in the dataset. 
The threshold value of 3 is a common choice, considering that data points beyond three standard deviations from the mean are considered unusual in a normal distribution. Adjusting the threshold allows for more or fewer data points to be flagged as outliers.
- Applies the .all(axis=1) operation along axis 1, which corresponds to the columns in the boolean array. This operation checks if all conditions are True for each row. 
The result is a boolean mask indicating whether all Z-scores for each data point are below the threshold.

```Python
# Define a threshold for the Z-score
z_threshold = 3
# Calculate the Z-scores for each column
z_scores = stats.zscore(diabetes_DS)

# Create a boolean mask for outliers
outlier_mask = (abs(z_scores) < z_threshold).all(axis=1)

# Filter the dataset to remove outliers
diabetes_DS2 = diabetes_DS[outlier_mask]

# Print information about the removed outliers
outliers_removed = diabetes_DS.shape[0] - diabetes_DS2.shape[0]
print(f"Number of outliers removed: {outliers_removed}")
```
Number of outliers removed: 80

**After z**

<CustomImage src="https://raw.githubusercontent.com/Bhargavoza1/projects/main/images/Diabetes-Prediction/boxplota.png"  alt=""  width={1000} height={800} />

## Feature Engineering

Categorizing BMI values into four groups (Underweight, Healthy, Overweight, and Obese). It then applies this function to each row of a DataFrame diabetes_DS2, creating a new column 'BM_DESC' to store the BMI descriptions.
```Python
def set_bmi(row):
    if row["BMI"] < 18.5:
        return "Under"
    elif row["BMI"] >= 18.5 and row["BMI"] <= 24.9:
        return "Healthy"
    elif row["BMI"] >= 25 and row["BMI"] <= 29.9:
        return "Over"
    elif row["BMI"] >= 30:
        return "Obese"

diabetes_DS2 = diabetes_DS2.assign(BM_DESC=diabetes_DS2.apply(set_bmi, axis=1))

diabetes_DS2.head()
```
<CustomImage src="https://raw.githubusercontent.com/Bhargavoza1/projects/main/images/Diabetes-Prediction/bmid.png"  alt=""  width={800} height={200} />

Categorizing insulin levels as "Normal" or "Abnormal" based on specific criteria. It then applies this function to each row of the DataFrame diabetes_DS2, creating a new column 'INSULIN_DESC'.
```python
def set_insulin(row):
    if row["Insulin"] >= 16 and row["Insulin"] <= 166:
        return "Normal"
    else:
        return "Abnormal"

diabetes_DS2 = diabetes_DS2.assign(INSULIN_DESC=diabetes_DS2.apply(set_insulin, axis=1))

diabetes_DS2.head()
```
<CustomImage src="https://raw.githubusercontent.com/Bhargavoza1/projects/main/images/Diabetes-Prediction/insulind.png"  alt=""  width={900} height={200} />

```python
sns.countplot(data=diabetes_DS2, x = 'INSULIN_DESC', label='Count')

AB, NB = diabetes_DS2['INSULIN_DESC'].value_counts()
print('Number of patients Having Abnormal Insulin Levels: ',AB)
print('Number of patients Having Normal Insulin Levels: ',NB)
```
Number of patients Having Abnormal Insulin Levels:  435\
Number of patients Having Normal Insulin Levels:  253

```python
sns.countplot(data=diabetes_DS2, x = 'BM_DESC', label='Count')

UD,H,OV,OB = diabetes_DS2['BM_DESC'].value_counts()
print('Number of patients Having Underweight BMI Index: ',UD)
print('Number of patients Having Healthy BMI Index: ',H)
print('Number of patients Having Overweigth BMI Index: ',OV)
print('Number of patients Having Obese BMI Index: ',OB)
```
Number of patients Having Underweight BMI Index:  424\
Number of patients Having Healthy BMI Index:  166\
Number of patients Having Overweigth BMI Index:  94\
Number of patients Having Obese BMI Index:  4

```python
diabetes_DS2.dtypes
```
<CustomImage src="https://raw.githubusercontent.com/Bhargavoza1/projects/main/images/Diabetes-Prediction/dtypesb.png"  alt=""  width={282} height={209} />

**get_dummies** function from the pandas library to perform one-hot encoding on the DataFrame diabetes_DS2. This function converts categorical variables into dummy/indicator variables, 
creating binary columns for each category and assigning 0 or 1 based on the presence of the category.
```python
diabetes_DS2 = pd.get_dummies(diabetes_DS2)
```
**pd.factorize** function to convert categorical variables into numerical representations for specific columns in the DataFrame diabetes_DS2.
```python
diabetes_DS2['BM_DESC_Healthy'] = pd.factorize(diabetes_DS2['BM_DESC_Healthy'])[0]
diabetes_DS2['BM_DESC_Obese'] = pd.factorize(diabetes_DS2['BM_DESC_Obese'])[0]
diabetes_DS2['BM_DESC_Over'] = pd.factorize(diabetes_DS2['BM_DESC_Over'])[0]
diabetes_DS2['INSULIN_DESC_Abnormal'] = pd.factorize(diabetes_DS2['INSULIN_DESC_Abnormal'])[0]
diabetes_DS2['INSULIN_DESC_Normal'] = pd.factorize(diabetes_DS2['INSULIN_DESC_Normal'])[0]
```

```python
diabetes_DS2.dtypes
```
The new features have been added to our dataset and converted every categorical variables into numerical variables.
<CustomImage src="https://raw.githubusercontent.com/Bhargavoza1/projects/main/images/Diabetes-Prediction/dtypesa.png"  alt=""  width={282} height={271} />

## Train Test split
```
cols_drop = ['Outcome','BM_DESC_Under']
X = diabetes_DS2.drop(cols_drop,axis=1)
Y = diabetes_DS2['Outcome']
```
Standardizing features helps these algorithms perform more efficiently and converge faster, leading to better overall model performance.

```python
scaler = StandardScaler()
X = scaler.fit_transform(X)
X[0:5]
```
<CustomImage src="https://raw.githubusercontent.com/Bhargavoza1/projects/main/images/Diabetes-Prediction/ss.png"  alt=""  width={512} height={512} />

```python
X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2, stratify=Y, random_state=42)
print(X.shape, X_train.shape, X_test.shape)
```
(688, 13) (550, 13) (138, 13)

## Logistic regression
Logistic regression, used with the cross-entropy cost function, is widely used in machine learning for binary classification like spam detection. Logistic regression employs the logistic function to provide probabilities between 0 and 1. 
The cross-entropy cost function measures dissimilarity between predicted probabilities and actual labels, facilitating accurate predictions. This combination offers a smooth, differentiable loss function, crucial for optimization methods like gradient descent. 
The goal is to find optimal parameters (global minimum) by iteratively adjusting them during training, enhancing the model's generalization to new data.

For a comprehensive explanation, kindly visit the following website:[logistic-regression](https://www.analyticsvidhya.com/blog/2021/08/conceptual-understanding-of-logistic-regression-for-data-science-beginners/) 

```python
logisticregression = LogisticRegression(max_iter=200)
```
```python
logisticregression.fit(X_train,Y_train)
```

Expression is calculating the accuracy of the logistic regression model on the training data and presenting it as a percentage rounded to two decimal places.
```python
round(logisticregression.score(X_train, Y_train)*100, 2)
```
79.09

Now, expression is calculating the accuracy on test data.
```python
round(logisticregression.score(X_test, Y_test)*100, 2)
```
78.99

Quick comparison between the actual and predicted values. 
```python
Y_pred = logisticregression.predict(X_test)
Y_test_pred = pd.DataFrame({
    'Y_test': Y_test,
    'Y_pred': Y_pred
})
Y_test_pred.head()
```

## Confusion matrix

A confusion matrix is a table that is often used to evaluate the performance of a classification model. It compares the predicted labels of a model with the actual labels, breaking down the results into four categories:
- True Positives (TP): Instances that were correctly predicted as positive. In a binary classification scenario, it means the model correctly identified the positive class.
- True Negatives (TN): Instances that were correctly predicted as negative. In a binary classification scenario, it means the model correctly identified the negative class.
- False Positives (FP): Instances that were incorrectly predicted as positive. In a binary classification scenario, it means the model predicted positive when the actual class was negative (Type I error).
- False Negatives (FN): Instances that were incorrectly predicted as negative. In a binary classification scenario, it means the model predicted negative when the actual class was positive (Type II error).

<CustomImage src="https://raw.githubusercontent.com/Bhargavoza1/projects/main/images/Diabetes-Prediction/cm.png"  alt=""  width={323} height={215} />
```python
conf_matrix = confusion_matrix(Y_test, Y_pred)
conf_matrix
```
array([[83,  9],[20, 26]], dtype=int64)

```python
# Plot the confusion matrix using seaborn
plt.figure(figsize=(2, 2))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()
```
<CustomImage src="https://raw.githubusercontent.com/Bhargavoza1/projects/main/images/Diabetes-Prediction/lrcm.png"  alt=""  width={218} height={237} />

##  Precision, Recall, and F1-score
Precision, recall, and F1-score are important metrics in classification tasks because they provide a more nuanced evaluation of a model's performance than accuracy alone. 
Each of these metrics addresses specific aspects of a model's behavior, and they become particularly relevant in situations where the class distribution is imbalanced or when the cost of different types of errors varies.

- **Precision(Positive Predictive Value):** Precision is the ratio of true positives to the total predicted positives. It answers the question: "Of all the instances predicted as positive, how many were actually positive?"
- **Recall (Sensitivity or True Positive Rate):** Recall is the ratio of true positives to the total actual positives. It answers the question: "Of all the actual positive instances, how many were correctly predicted?"
- **F1-score:** The F1-score is the harmonic mean of precision and recall. It provides a balanced measure that considers both false positives and false negatives.


```python
print(classification_report(Y_test, Y_pred))
```

Let's calculate precision, recall, and F1-score for both classes (0 and 1) 
1. Precision for Class 0: $P = \frac{TN}{TN + FN} = \frac{83}{83 + 20} \approx 0.805$
2. Recall for Class 0: $R = \frac{TN}{TN + FP} = \frac{83}{83 + 9} \approx 0.902$
3. F1-score for Class 0: $F1_c0 = 2 \times \frac{Precision_c0 \times Recall_c0}{Precision_c0 + Recall_c0} = 2 \times \frac{0.805 \times 0.902}{0.805 + 0.902} \approx 0.851 $
4. Precision for Class 1: $P = \frac{TP}{TP + FP} = \frac{26}{26 + 9} \approx 0.743$
5. Recall for Class 1: $R = \frac{TP}{TP + FN} = \frac{26}{26 + 20} \approx 0.565$
6. F1-score for Class 1:$F1_c1 = 2 \times \frac{Precision_c1 \times Recall_c1}{Precision_c1 + Recall_c1} = 2 \times \frac{0.743 \times 0.565}{0.743 + 0.565} \approx 0.643$